{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Report - First Machine Learning Project\n",
    "\n",
    "##### Nakul Pandit\n",
    "##### 250919679"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Index: <a id='index'></a>\n",
    "1. [Building a Machine Learning Model](#model)\n",
    "1. [The dataset](#dataset)\n",
    "1. [Decision Trees](#DT)\n",
    "1. [Expectations](#expectations)\n",
    "1. [Nearest Neighbours](#knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Section 1: Building a Machine Learning Model  [^](#index) <a id='model'></a>\n",
    "\n",
    "Steps:\n",
    "1. **Problem formulation:** \n",
    "2. **Data collection:** \n",
    "3. **Data preparation and feature engineering:** \n",
    "4. **Model selection and training:** \n",
    "5. **Model evaluation:** \n",
    "6. **Model tuning:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Problem formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, **define the problem that we want to solve**. Are we trying to predict? Or classify? Do you think we should use supervised learning or unsupervised learning for this task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"Iris Dataset\"-** For the Iris dataset, the task is to classify each flower sample into one of three species (Setosa, Versicolor, Virginica). We will classify it based on four measured features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PtFRH2i99xOv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sz-MkQli_ve8"
   },
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Section 2: The dataset [^](#index) <a id='dataset'></a>\n",
    "\n",
    "### 2.1 Find the appropriate dataset\n",
    "In the second step, we collect the data that we need to train our model. In this case we were lucky and the [Habitable Worlds Catalogue]('https://phl.upr.edu/hwc') has done this for us already. It lists up to potentially habitable worlds in a list of over five thousand known exoplanets, putting together information gathered by several observatories, including the Kepler and K2 missions and the ongoing Transiting Exoplanet Survey Satellite.\n",
    "\n",
    "As this is our very first machine learning project, it may be daunting to look at a 5000+ dataset with tens of features, so I made smaller set for you, made of 18 instances, 3 features and our target labels. This is in the csv file called `HabPlanets_simple.csv`.\n",
    "\n",
    "### 2.2 Read the dataset\n",
    "In week 1, you learned to use the `read_csv` function from the `panda` module, so I left the cell below for you to complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1704972145100,
     "user": {
      "displayName": "Linda Cremonesi",
      "userId": "14767435952218470727"
     },
     "user_tz": 0
    },
    "id": "eANzm4IHQjCj",
    "outputId": "0bb451d7-4e61-48a7-b483-3144052c6bdf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_NAME</th>\n",
       "      <th>P_MASS</th>\n",
       "      <th>P_MASS_ERROR_MIN</th>\n",
       "      <th>P_MASS_ERROR_MAX</th>\n",
       "      <th>P_RADIUS</th>\n",
       "      <th>P_RADIUS_ERROR_MIN</th>\n",
       "      <th>P_RADIUS_ERROR_MAX</th>\n",
       "      <th>P_YEAR</th>\n",
       "      <th>P_UPDATED</th>\n",
       "      <th>P_PERIOD</th>\n",
       "      <th>...</th>\n",
       "      <th>S_ABIO_ZONE</th>\n",
       "      <th>S_TIDAL_LOCK</th>\n",
       "      <th>P_HABZONE_OPT</th>\n",
       "      <th>P_HABZONE_CON</th>\n",
       "      <th>P_TYPE_TEMP</th>\n",
       "      <th>P_HABITABLE</th>\n",
       "      <th>P_ESI</th>\n",
       "      <th>S_CONSTELLATION</th>\n",
       "      <th>S_CONSTELLATION_ABR</th>\n",
       "      <th>S_CONSTELLATION_ENG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OGLE-2016-BLG-1227L b</td>\n",
       "      <td>251.084120</td>\n",
       "      <td>-123.952920</td>\n",
       "      <td>413.176400</td>\n",
       "      <td>13.90040</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cold</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146639</td>\n",
       "      <td>Scorpius</td>\n",
       "      <td>Sco</td>\n",
       "      <td>Scorpion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kepler-276 c</td>\n",
       "      <td>16.527056</td>\n",
       "      <td>-3.496108</td>\n",
       "      <td>4.449592</td>\n",
       "      <td>2.90339</td>\n",
       "      <td>-0.28025</td>\n",
       "      <td>1.26673</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "      <td>31.884000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.097783</td>\n",
       "      <td>0.316980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hot</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271883</td>\n",
       "      <td>Cygnus</td>\n",
       "      <td>Cyg</td>\n",
       "      <td>Swan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kepler-829 b</td>\n",
       "      <td>5.085248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.10748</td>\n",
       "      <td>-0.17936</td>\n",
       "      <td>0.43719</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>6.883376</td>\n",
       "      <td>...</td>\n",
       "      <td>1.756317</td>\n",
       "      <td>0.459559</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hot</td>\n",
       "      <td>0</td>\n",
       "      <td>0.254888</td>\n",
       "      <td>Lyra</td>\n",
       "      <td>Lyr</td>\n",
       "      <td>Lyre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K2-283 b</td>\n",
       "      <td>12.172812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.51994</td>\n",
       "      <td>-0.15694</td>\n",
       "      <td>0.15694</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.921036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hot</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193908</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>Psc</td>\n",
       "      <td>Fishes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kepler-477 b</td>\n",
       "      <td>4.926334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.07385</td>\n",
       "      <td>-0.12331</td>\n",
       "      <td>0.17936</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>11.119907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768502</td>\n",
       "      <td>0.386150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hot</td>\n",
       "      <td>0</td>\n",
       "      <td>0.276524</td>\n",
       "      <td>Lyra</td>\n",
       "      <td>Lyr</td>\n",
       "      <td>Lyre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>Kepler-58 e</td>\n",
       "      <td>3.210063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.69271</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>4.458149</td>\n",
       "      <td>...</td>\n",
       "      <td>3.550861</td>\n",
       "      <td>0.453699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hot</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273785</td>\n",
       "      <td>Cygnus</td>\n",
       "      <td>Cyg</td>\n",
       "      <td>Swan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>KMT-2019-BLG-1216L b</td>\n",
       "      <td>29.875832</td>\n",
       "      <td>-15.891400</td>\n",
       "      <td>15.891400</td>\n",
       "      <td>5.97493</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cold</td>\n",
       "      <td>0</td>\n",
       "      <td>0.287181</td>\n",
       "      <td>Scorpius</td>\n",
       "      <td>Sco</td>\n",
       "      <td>Scorpion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>TOI-1694 b</td>\n",
       "      <td>26.100035</td>\n",
       "      <td>-2.199370</td>\n",
       "      <td>2.199370</td>\n",
       "      <td>5.43685</td>\n",
       "      <td>-0.17936</td>\n",
       "      <td>0.17936</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>3.770150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hot</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Camelopardalis</td>\n",
       "      <td>Cam</td>\n",
       "      <td>Giraffe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>KMT-2022-BLG-0440L b</td>\n",
       "      <td>15.398767</td>\n",
       "      <td>-7.399036</td>\n",
       "      <td>9.598406</td>\n",
       "      <td>4.04681</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Warm</td>\n",
       "      <td>0</td>\n",
       "      <td>0.414763</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>Sgr</td>\n",
       "      <td>Archer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>HD 222155 b</td>\n",
       "      <td>581.625240</td>\n",
       "      <td>-82.635280</td>\n",
       "      <td>111.239800</td>\n",
       "      <td>13.45200</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2011</td>\n",
       "      <td>2012</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.893917</td>\n",
       "      <td>0.541322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cold</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178331</td>\n",
       "      <td>Andromeda</td>\n",
       "      <td>And</td>\n",
       "      <td>Andromeda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5566 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     P_NAME      P_MASS  P_MASS_ERROR_MIN  P_MASS_ERROR_MAX  \\\n",
       "0     OGLE-2016-BLG-1227L b  251.084120       -123.952920        413.176400   \n",
       "1              Kepler-276 c   16.527056         -3.496108          4.449592   \n",
       "2              Kepler-829 b    5.085248          0.000000          0.000000   \n",
       "3                  K2-283 b   12.172812          0.000000          0.000000   \n",
       "4              Kepler-477 b    4.926334          0.000000          0.000000   \n",
       "...                     ...         ...               ...               ...   \n",
       "5561            Kepler-58 e    3.210063          0.000000          0.000000   \n",
       "5562   KMT-2019-BLG-1216L b   29.875832        -15.891400         15.891400   \n",
       "5563             TOI-1694 b   26.100035         -2.199370          2.199370   \n",
       "5564   KMT-2022-BLG-0440L b   15.398767         -7.399036          9.598406   \n",
       "5565            HD 222155 b  581.625240        -82.635280        111.239800   \n",
       "\n",
       "      P_RADIUS  P_RADIUS_ERROR_MIN  P_RADIUS_ERROR_MAX  P_YEAR  P_UPDATED  \\\n",
       "0     13.90040             0.00000             0.00000    2020       2020   \n",
       "1      2.90339            -0.28025             1.26673    2013       2014   \n",
       "2      2.10748            -0.17936             0.43719    2016       2016   \n",
       "3      3.51994            -0.15694             0.15694    2018       2018   \n",
       "4      2.07385            -0.12331             0.17936    2016       2016   \n",
       "...        ...                 ...                 ...     ...        ...   \n",
       "5561   1.69271             0.00000             0.00000    2023       2023   \n",
       "5562   5.97493             0.00000             0.00000    2023       2023   \n",
       "5563   5.43685            -0.17936             0.17936    2023       2023   \n",
       "5564   4.04681             0.00000             0.00000    2023       2023   \n",
       "5565  13.45200             0.00000             0.00000    2011       2012   \n",
       "\n",
       "         P_PERIOD  ...  S_ABIO_ZONE  S_TIDAL_LOCK  P_HABZONE_OPT  \\\n",
       "0        0.000000  ...     0.000046      0.000000              0   \n",
       "1       31.884000  ...     2.097783      0.316980              0   \n",
       "2        6.883376  ...     1.756317      0.459559              0   \n",
       "3        1.921036  ...     0.568374      0.000000              0   \n",
       "4       11.119907  ...     0.768502      0.386150              0   \n",
       "...           ...  ...          ...           ...            ...   \n",
       "5561     4.458149  ...     3.550861      0.453699              0   \n",
       "5562     0.000000  ...     0.000072      0.000000              0   \n",
       "5563     3.770150  ...     0.563688      0.000000              0   \n",
       "5564     0.000000  ...     0.000080      0.000000              1   \n",
       "5565  3999.000000  ...     1.893917      0.541322              0   \n",
       "\n",
       "      P_HABZONE_CON  P_TYPE_TEMP  P_HABITABLE     P_ESI  S_CONSTELLATION  \\\n",
       "0                 0         Cold            0  0.146639         Scorpius   \n",
       "1                 0          Hot            0  0.271883           Cygnus   \n",
       "2                 0          Hot            0  0.254888             Lyra   \n",
       "3                 0          Hot            0  0.193908           Pisces   \n",
       "4                 0          Hot            0  0.276524             Lyra   \n",
       "...             ...          ...          ...       ...              ...   \n",
       "5561              0          Hot            0  0.273785           Cygnus   \n",
       "5562              0         Cold            0  0.287181         Scorpius   \n",
       "5563              0          Hot            0       NaN   Camelopardalis   \n",
       "5564              1         Warm            0  0.414763      Sagittarius   \n",
       "5565              0         Cold            0  0.178331        Andromeda   \n",
       "\n",
       "      S_CONSTELLATION_ABR  S_CONSTELLATION_ENG  \n",
       "0                     Sco             Scorpion  \n",
       "1                     Cyg                 Swan  \n",
       "2                     Lyr                 Lyre  \n",
       "3                     Psc               Fishes  \n",
       "4                     Lyr                 Lyre  \n",
       "...                   ...                  ...  \n",
       "5561                  Cyg                 Swan  \n",
       "5562                  Sco             Scorpion  \n",
       "5563                  Cam              Giraffe  \n",
       "5564                  Sgr               Archer  \n",
       "5565                  And            Andromeda  \n",
       "\n",
       "[5566 rows x 103 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LearningSet = pd.read_csv('hwc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bx1xNCSv_ve9"
   },
   "source": [
    "### 2.3 Check that the dataset has been read correctly\n",
    "\n",
    "Check that your dataset has been read correctly by exploring its structure (displaying the whole `LearningSet`, and using `head()` or `describe(`). **NB You shouldn't be plotting the dataset at this stage as you have not split it into the training and test set yet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1704972148924,
     "user": {
      "displayName": "Linda Cremonesi",
      "userId": "14767435952218470727"
     },
     "user_tz": 0
    },
    "id": "kQ_lxc3V_ve9",
    "outputId": "03e5f755-697d-4de0-a880-6c5c0e004b65"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Understand the features \n",
    "The dataset includes 3 features and one target. Looking at the website source we can see that the column features refer to:\n",
    " - S_MASS - star mass (solar units).\n",
    " - P_PERIOD - planet period (days).\n",
    " - P_DISTANCE - planet mean distance from the star (AU).\n",
    " - P_HABITABLE - boolean variable telling us if the planet is habitable or not.\n",
    "\n",
    "You can change the column names to something handier, or keep them as they are, the important thing is that you remember what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "## Exercise 1\n",
    "When dealing with a new dataset it's useful to answer these questions.\n",
    "1. What's the size of the dataset?\n",
    "2. Are there any missing data? if yes, how should you handle them?\n",
    "3. Are all the features in a similar numerical range and is there anything unusual about the distribution of the numerical values?\n",
    "4. Is the dataset imbalanced (ie one or more classes are much more heavily populated than others)?\n",
    "5. Start developing some intuition on how well you expect the model to work: are these features meaningful? do we have enough samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJIpQEk01A7i"
   },
   "source": [
    "## 1.3 Data preparation and feature engineering\n",
    "\n",
    "This step involves preparing the data for training, such as cleaning and transforming it. This may involve removing outliers, imputing missing values, and normalising the data. Select the features that are most important for the problem. This may involve creating new features or removing irrelevant features.\n",
    "\n",
    "### 1.3.1 Splitting between the Train and Test set\n",
    "The first thing we will want to do is split the data set into training and test sets. Normally the train/test split choice happens at random, but for this notebook we will choose a specific split so that the results are reproducible.\n",
    "Use the first 13 instances of the dataframe as a train set and the last 5 as a test set (*hint: you could use the `panda` method `iloc` for this)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1j5xrsN1A7j"
   },
   "outputs": [],
   "source": [
    "TrainSet = ...\n",
    "TestSet = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create `Xtrain` and `Xtest` sets which will not have the name and habitable columns (*hint: you can use `drop` to do this*). And create your label sets `ytrain` and `ytest` which will only include the habitable column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = ...\n",
    "Xtest = ...\n",
    "ytrain = ...\n",
    "ytest  = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the `shape` of `Xtrain`, `Xtest`, `ytrain`, `ytest` is what you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1704972904082,
     "user": {
      "displayName": "Linda Cremonesi",
      "userId": "14767435952218470727"
     },
     "user_tz": 0
    },
    "id": "axXzrd5A1A7j",
    "outputId": "76883880-86b5-4559-84f2-71d9d21c2195"
   },
   "outputs": [],
   "source": [
    "Xtrain.shape, Xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QROXGJ7D1A7j"
   },
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "## Exercise 2\n",
    "Plot the train and test set in a nice scatter graph. I added some bits of code which I know will make the plot prettier once you have correctly defined everything. We want the following features:\n",
    "1. Plot a scatter graph of the `Xtrain` dataset (mass of parent star on the x-axis and the orbital period on the y axis), and using the `ytrain` as the `c` option for the colormap (`cmap` has already been defined for you below), `*` as markers, and an `alpha` of 0.5. We will want to label this `Train`.\n",
    "2. Add a scatter graph of the `Xtest` dataset (mass of parent star on the x-axis and the orbital period on the y axis), and using the `ytest` as the `c` option for the colormap, `o` as markers, and an `alpha` of 0.5. We will want to label this `Test`.\n",
    "3. Add descriptive axis labels (including units)\n",
    "4. The y axis should be in a logarithmic scale\n",
    "5. Plot the legend\n",
    "\n",
    "3. Using `plt.axvline` and `plt.axhline` plot a horizontal line at 3.5 and a vertical line at 0.5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2915,
     "status": "ok",
     "timestamp": 1704973932176,
     "user": {
      "displayName": "Linda Cremonesi",
      "userId": "14767435952218470727"
     },
     "user_tz": 0
    },
    "id": "21LZWtZg1A7j",
    "outputId": "573d06e7-9719-4fcd-ac64-82d7f3dd2eed"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "cmap = colors.ListedColormap(['purple', 'green'])\n",
    "\n",
    "...\n",
    "\n",
    "purplepatch = mpatches.Patch(color='purple', label='Not Habitable')\n",
    "greenpatch = mpatches.Patch(color='green', label='Habitable')\n",
    "\n",
    "ax = plt.gca()\n",
    "leg = ax.get_legend()\n",
    "leg.legend_handles[0].set_color('k')\n",
    "leg.legend_handles[1].set_color('k')\n",
    "plt.legend(handles=[leg.legend_handles[0],leg.legend_handles[1], purplepatch, greenpatch])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Section 3: Decision Trees  [^](#index) <a id='DT'></a>\n",
    "\n",
    "\n",
    "A decision tree is a type of machine learning algorithm that uses a tree-like structure to make decisions or predictions. It's often used in supervised learning tasks, (where you have a dataset with labeled examples and you want to learn a model that can predict the labels for new, unseen examples).\n",
    "\n",
    "Here's how a decision tree works:\n",
    " - **Start at the root node.** This node represents the entire dataset.\n",
    " - **Ask a question about one of the features in the data.** The answer to the question will determine which branch of the tree to take.\n",
    " - **Continue asking questions and following branches until you reach a leaf node.** The leaf node represents a prediction or classification.\n",
    "\n",
    "A good decision is characterised by efficient splits, which has the maximum information gain or maximum decrease of impurity. A metric that is often is used is the **Gini impurity** defined as:\n",
    "$$\n",
    " I_G = 1 - \\sum_i f(i)^2\n",
    "$$\n",
    "where $f(i)$ is the fractional abundance of each class.\n",
    "\n",
    "To calculate if a split is convenient or not, we need to perform 3 steps:\n",
    "1. Calculate the Gini impurity of the current dataset.\n",
    "2. Calculate the Gini impurity of the proposed split.\n",
    "3. Calculate the difference between the two.\n",
    "\n",
    "The largest decrease in impurity will be the preferable option. **NB. The Gini impurity of a proposed split is the sum of the fractional impurities of the two resulting nodes, weighted by the fractional volume of each node with respect to its parent node.**\n",
    "\n",
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "## Exercise 3\n",
    "Using the two lines defined in the scatter plot above and the definition of the Gini impurity, assess whether it is more convenient to split the **train** dataset vertically and then horizontally or the other way round. When calculting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model!\n",
    "It's time to train our Decision Tree and see if our model finds our same results. The following cells does two things:\n",
    " - It defines our model as our decision tree classifier\n",
    " - It then trains the model with out train set\n",
    "The `random_state` variable in this case is set to a specific value for reproducibility purposes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1704973387588,
     "user": {
      "displayName": "Linda Cremonesi",
      "userId": "14767435952218470727"
     },
     "user_tz": 0
    },
    "id": "CHd_hfFX1A7k",
    "outputId": "585f30f6-97ab-4aab-bb7a-b352c3300b52"
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=3)\n",
    "model.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emzs5EuC1A7k"
   },
   "source": [
    "#### Let's visualize the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(model, feature_names=['Stellar Mass (M*)', 'Orbital Period (d)', 'Distance (AU)'], \n",
    "          class_names=['Not Habitable','Habitable'], filled = True, rounded = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zguGgjVW1A7l"
   },
   "source": [
    "These numbers are a little bit different from what we found above. Can you guess why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we only looked at 2 features, whereas the DT is looking at 3 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zguGgjVW1A7l"
   },
   "source": [
    "### Let's take a look at some metrics.\n",
    "Using the `model.predict` function, apply the model to `Xtest` and calculate our prediction on the test set and on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytestpred = ...\n",
    "ytrainpred = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `metrics` module you can calculate the `accuracy_score` and compare the performance of the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "elapsed": 229,
     "status": "error",
     "timestamp": 1704974742242,
     "user": {
      "displayName": "Linda Cremonesi",
      "userId": "14767435952218470727"
     },
     "user_tz": 0
    },
    "id": "Op3ELHmg1A7l",
    "outputId": "94395968-f93b-4a8f-aafa-fadfadeb6f1c"
   },
   "outputs": [],
   "source": [
    "test_accuracy  = ...\n",
    "train_accuracy = ...\n",
    "print(\"The accuracy of the test set is {:.3f}\".format(test_accuracy))\n",
    "print(\"The accuracy of the train set is {:.3f}\".format(train_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells make a pretty Confusion Matrix and print out the number of true negatives, true positives, false negatives and false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(ytest,ytestpred, labels=model.classes_)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                               display_labels=['Not Habitable','Habitable'])\n",
    "disp.plot()\n",
    "\n",
    "print(\"Number of True Negatives: {:.3f}\".format(cm[0,0]))\n",
    "print(\"Number of True Positives: {:.3f}\".format(cm[1,1]))\n",
    "print(\"Number of False Negatives: {:.3f}\".format(cm[1,0]))\n",
    "print(\"Number of False Positives: {:.3f}\".format(cm[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "## Exercise 4\n",
    "Repeat the same exercise but with taking the first 5 instances of the `LearningSet` as our test set and the last 13 as our training set:\n",
    "1. Plot a scatter graph of the new train set and test set.\n",
    "2. Train the new model (using again `random_state=3` to have reproducibility)\n",
    "3. Visualise the decision tree\n",
    "4. Calculate and display the new accuracy\n",
    "5. Discuss which training is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Section 4: Nearest Neighbours  [^](#index) <a id='neighbor'></a>\n",
    "\n",
    "The nearest neighbour method, also known as the k-nearest neighbours (k-NN) algorithm, is a simple yet powerful technique in machine learning used for both classification and regression tasks. It works on the fundamental assumption that similar data points are likely to have similar labels or values.\n",
    "We can use it in a similar way just by calling the classifier from `scikit-learn`. In this case we use the `KNeighborsClassifier`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "## Exercise 5\n",
    "\n",
    "1. Define the new model as the `KNeighborsClassifier` using the option of `n_neighbor=3` (we use just 3 neighbors as this is a very small dataset, the default is 5 neighbours). Train the dataset using the `fit` method as you've done previously.\n",
    "2. Use the `predict` method from the model to get the predictions and calculate the accuracy scores.\n",
    "3. Plot the confusion matrix and print out the number of true positives, true negatives, false positives, false negatives.\n",
    "4. What do you think about this classifier? did it work well?\n",
    "5. Plot the scatter graph of the test and train set again (yes the usual one!) but without the logarithmic y-axis. Then, use the code below to plot the 5 circles representing the circle of the closest 3 instances to the 5 test points. (Yes, I am giving you the code for this one!). Does this explain the results of the training?\n",
    "\n",
    "```\n",
    "dist, ind = model.kneighbors(Xtest)\n",
    "\n",
    "for index in range(5):\n",
    "    x0 = TestSet.loc[index, 'S_MASS']\n",
    "    y0 = TestSet.loc[index, 'P_PERIOD']\n",
    "    r0 = dist[index].max()\n",
    "    circle=plt.Circle((x0, y0), r0, color='r', fill=False)\n",
    "    ax = plt.gca()\n",
    "    ax.add_patch(circle)\n",
    "\n",
    "plt.xlim(-10, 10)\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training performed better as the features now weigh a similar amount and the dataset is not skewed towards the features with highest numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Preprocessing and Scaling\n",
    "\n",
    "Hopefully you have now noticed that one of our features has much larger numerical values than the others, so it takes more weight in the machine learning process. Note that this was not a problem for the Decision Tree, as the decisions were made one at a time.\n",
    "\n",
    "There are a few different options to define a scaler as you have seen in the notes. We will start with a `RobustScaler`, then we use the `fit` method to compute the median and quartiles of the set and scale the set so that the median in 0 and the quartiles are appropriately distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.RobustScaler()\n",
    "scaler.fit(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply this transformation, ie to *scale* the training data, we use the `transform` method of the scaler. The `transform` method is used in `scikit-learn` whenever a model returns a new representation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledXtrain = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the dataset properties** (median, 0.25, 0.75 quantiles) before and after the scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformed data has the same shape as the original data - the features are simply shifted and scaled.\n",
    "\n",
    "To apply the kNN to the scaled data we need to **apply** the same transformation to the test set as well. **It is important not to use the test set to make the transformation as we don't want to *see* the test set statistical properties**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledXtest  = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print test set properties before and after the scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "## Exercise 6\n",
    "\n",
    "1. Retrain the neighbour classifier with your new scaled training set. \n",
    "2. Calculate the new accuracy.\n",
    "3. Calculate the new confusion matrix and true positives/negatives, false positives/negatives.\n",
    "4. Remake the scatter plot with the circles.\n",
    "5. Write a short sentence with your thoughts on the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMkwsRbr6kfahxKh5Bqc6MT",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
